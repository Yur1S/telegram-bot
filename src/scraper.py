import requests
import json
from typing import List, Dict, Optional
import logging
import pandas as pd
import os
from datetime import datetime, timedelta
import schedule
import time
import threading
import asyncio

logger = logging.getLogger(__name__)

class ProductScraper:
    def __init__(self):
        logger.info("Initializing ProductScraper...")
        self.EAEU_API_URL = "https://goszakupki.eaeunion.org/spd/find"
        self.GISP_EXCEL_URL = "https://gisp.gov.ru/documents/10546/11962150/reestr_pprf_719_27122023.xlsx"
        self.GISP_FILE_PATH = "data/gisp_products.csv"
        self.last_update = None
        self.file_update_status = None
        self.chunk_size = 50000
        self.df_cache = None
        self.search_index = {}  # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω–¥–µ–∫—Å –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞
        
        os.makedirs(os.path.dirname(self.GISP_FILE_PATH), exist_ok=True)
        self.start_background_updates()
        
        if not os.path.exists(self.GISP_FILE_PATH):
            logger.info("GISP file not found, downloading...")
            self.download_gisp_file()
        logger.info("ProductScraper initialized successfully")

    async def download_gisp_file_with_status(self, status_message):
        temp_file = "data/temp_gisp.xlsx"
        try:
            # –≠—Ç–∞–ø 1: –°–∫–∞—á–∏–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞
            logger.info("Starting GISP file download...")
            await status_message.edit_text("‚è≥ –°–∫–∞—á–∏–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞ –ì–ò–°–ü...")
            
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                'Accept': '*/*',
                'Accept-Language': 'ru-RU,ru;q=0.9,en-US;q=0.8,en;q=0.7',
                'Accept-Encoding': 'gzip, deflate, br',
                'Connection': 'keep-alive',
                'Referer': 'https://gisp.gov.ru/',
            }

            self.GISP_EXCEL_URL = "https://gisp.gov.ru/pp719v2/mptapp/view/dl/production_res_valid_only/"
            
            try:
                response = requests.get(self.GISP_EXCEL_URL, headers=headers, verify=True, timeout=60)
                response.raise_for_status()
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º Excel —Ñ–∞–π–ª
                with open(temp_file, 'wb') as f:
                    f.write(response.content)
                
                if not os.path.exists(temp_file) or os.path.getsize(temp_file) == 0:
                    raise Exception("Failed to download file or file is empty")
                
                logger.info(f"Excel file downloaded successfully, size: {os.path.getsize(temp_file)} bytes")
                
            except Exception as e:
                logger.error(f"Download failed: {str(e)}")
                raise Exception(f"Failed to download file: {str(e)}")

            # –≠—Ç–∞–ø 2: –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞
            # –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ Excel
            await status_message.edit_text("‚è≥ –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞ Excel...")
            try:
                logger.info(f"Starting Excel processing, file size: {os.path.getsize(temp_file)} bytes")
                
                # –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ pandas
                pd.options.mode.chained_assignment = None
                chunk_size = 5000  # –£–º–µ–Ω—å—à–∞–µ–º —Ä–∞–∑–º–µ—Ä —á–∞–Ω–∫–∞ –µ—â–µ –±–æ–ª—å—à–µ
                
                # –ß–∏—Ç–∞–µ–º —Ç–æ–ª—å–∫–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –∫–æ–ª–æ–Ω–∫–∏ —Å –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ —Ç–∏–ø–∞–º–∏ –¥–∞–Ω–Ω—ã—Ö
                df_iterator = pd.read_excel(
                    temp_file,
                    usecols=[0, 1, 6, 8, 9, 11, 12, 13, 14],
                    skiprows=2,
                    names=[
                        '–ü—Ä–µ–¥–ø—Ä–∏—è—Ç–∏–µ', '–ò–ù–ù', '–†–µ–µ—Å—Ç—Ä–æ–≤—ã–π –Ω–æ–º–µ—Ä', 
                        '–î–∞—Ç–∞ –≤–Ω–µ—Å–µ–Ω–∏—è –≤ —Ä–µ–µ—Å—Ç—Ä', '–°—Ä–æ–∫ –¥–µ–π—Å—Ç–≤–∏—è',
                        '–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–¥—É–∫—Ü–∏–∏', '–û–ö–ü–î2', '–¢–ù –í–≠–î', '–ò–∑–≥–æ—Ç–æ–≤–ª–µ–Ω–∞ –ø–æ'
                    ],
                    engine='openpyxl',
                    dtype={
                        '–ò–ù–ù': str,
                        '–†–µ–µ—Å—Ç—Ä–æ–≤—ã–π –Ω–æ–º–µ—Ä': str,
                        '–û–ö–ü–î2': str,
                        '–¢–ù –í–≠–î': str,
                        '–ü—Ä–µ–¥–ø—Ä–∏—è—Ç–∏–µ': str,
                        '–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–¥—É–∫—Ü–∏–∏': str,
                        '–ò–∑–≥–æ—Ç–æ–≤–ª–µ–Ω–∞ –ø–æ': str
                    },
                    chunksize=chunk_size
                )

                # –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —á–∞–Ω–∫–æ–≤
                first_chunk = True
                total_rows = 0
                
                with open(self.GISP_FILE_PATH, 'w', encoding='utf-8-sig', newline='') as f:
                    for i, chunk in enumerate(df_iterator):
                        # –û—á–∏—â–∞–µ–º –ø–∞–º—è—Ç—å –ø–µ—Ä–µ–¥ –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –Ω–æ–≤–æ–≥–æ —á–∞–Ω–∫–∞
                        import gc
                        gc.collect()
                        
                        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —á–∞–Ω–∫
                        chunk = chunk.dropna(how='all')
                        
                        # –°–æ–∑–¥–∞–µ–º –∏–Ω–¥–µ–∫—Å—ã —Ç–æ–ª—å–∫–æ –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ —á–∞–Ω–∫–∞
                        if first_chunk:
                            chunk.to_csv(f, index=False)
                            first_chunk = False
                        else:
                            chunk.to_csv(f, index=False, header=False)
                        
                        total_rows += len(chunk)
                        await status_message.edit_text(f"‚è≥ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Å—Ç—Ä–æ–∫: {total_rows:,}")
                        
                        # –û—á–∏—â–∞–µ–º –ø–∞–º—è—Ç—å
                        del chunk
                        gc.collect()

                logger.info(f"CSV file saved successfully, total rows: {total_rows}")
                
                # –û–±–Ω–æ–≤–ª—è–µ–º –∏–Ω–¥–µ–∫—Å—ã —á–∞—Å—Ç—è–º–∏
                await status_message.edit_text("‚è≥ –°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–æ–≤ –ø–æ–∏—Å–∫–∞...")
                self._update_search_index_by_chunks()
                
                # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
                if os.path.exists(temp_file):
                    os.remove(temp_file)
                
                await status_message.edit_text("‚úÖ –§–∞–π–ª –ì–ò–°–ü —É—Å–ø–µ—à–Ω–æ –æ–±–Ω–æ–≤–ª–µ–Ω!")
                self.last_update = datetime.now()
                
                # –ó–∞–≥—Ä—É–∂–∞–µ–º –Ω–µ–±–æ–ª—å—à—É—é —á–∞—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö –≤ –∫—ç—à
                self.df_cache = pd.read_csv(
                    self.GISP_FILE_PATH, 
                    encoding='utf-8-sig',
                    dtype={
                        '–ò–ù–ù': str,
                        '–†–µ–µ—Å—Ç—Ä–æ–≤—ã–π –Ω–æ–º–µ—Ä': str,
                        '–û–ö–ü–î2': str,
                        '–¢–ù –í–≠–î': str
                    },
                    nrows=1000
                )
                
                return total_rows
                
            except Exception as e:
                logger.error(f"Excel processing failed: {str(e)}", exc_info=True)
                await status_message.edit_text(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞: {str(e)}")
                raise
                
        except Exception as e:
            logger.error(f"GISP file download failed: {str(e)}", exc_info=True)
            await status_message.edit_text(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Ñ–∞–π–ª–∞: {str(e)}")
            return 0

    def search_eaeu(self, okpd2: Optional[str] = None, name: Optional[str] = None) -> List[Dict]:
        try:
            logger.info(f"Starting EAEU search with okpd2={okpd2}, name={name}")
            params = {
                "collection": "db1.v_goodscollection_prod_public",
                "limit": 1000,
                "skip": 0,
                "sort": {"publishdate": -1}
            }

            query_filter = {}
            if okpd2:
                query_filter["okpd2.code"] = {"$regex": f"^{okpd2}", "$options": "i"}
            if name:
                query_filter["name"] = {"$regex": name, "$options": "i"}

            if query_filter:
                params["filter"] = query_filter

            response = requests.post(self.EAEU_API_URL, json=params)
            response.raise_for_status()
            
            data = response.json()
            
            results = []
            for item in data.get('items', []):
                result = {
                    'name': item.get('name', ''),
                    'okpd2_code': item.get('okpd2', {}).get('code', ''),
                    'manufacturer': item.get('manufacturer', {}).get('name', ''),
                    'inn': '',
                    'registry_number': '',
                    'registry_date': '',
                    'valid_until': '',
                    'tn_ved': '',
                    'standard': '',
                    'source': '–ï–ê–≠–°'
                }
                results.append(result)
            
            logger.info(f"EAEU search completed, found {len(results)} results")
            return results

        except Exception as e:
            logger.error(f"EAEU API search error: {e}")
            return []

    async def search_all(self, okpd2: Optional[str] = None, name: Optional[str] = None, status_message=None) -> List[Dict]:
        try:
            logger.info(f"Starting combined search with okpd2={okpd2}, name={name}")
            
            if status_message:
                await status_message.edit_text(
                    "üîç –ü–æ–∏—Å–∫ –≤ –ï–ê–≠–°...\n"
                    "‚è≥ –ü—Ä–æ–≥—Ä–µ—Å—Å: 0%"
                )
            eaeu_results = self.search_eaeu(okpd2, name)
            
            if status_message:
                await status_message.edit_text(
                    "üîç –ü–æ–∏—Å–∫ –≤ –ì–ò–°–ü...\n"
                    "‚è≥ –ü—Ä–æ–≥—Ä–µ—Å—Å: 50%"
                )
            gisp_results = await self.search_gisp(okpd2, name, status_message)
            
            total_results = eaeu_results + gisp_results
            
            if status_message:
                await status_message.edit_text(
                    f"‚úÖ –ü–æ–∏—Å–∫ –∑–∞–≤–µ—Ä—à–µ–Ω\n"
                    f"üìä –í—Å–µ–≥–æ –Ω–∞–π–¥–µ–Ω–æ: {len(total_results)}\n"
                    f"–ï–ê–≠–°: {len(eaeu_results)}\n"
                    f"–ì–ò–°–ü: {len(gisp_results)}\n\n"
                    f"–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ /start –¥–ª—è –Ω–æ–≤–æ–≥–æ –ø–æ–∏—Å–∫–∞"
                )
            
            logger.info(f"Combined search completed, total results: {len(total_results)}")
            return total_results
            
        except Exception as e:
            logger.error(f"Combined search error: {e}")
            if status_message:
                await status_message.edit_text(
                    f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ: {str(e)}\n\n"
                    f"–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ /start –¥–ª—è –Ω–æ–≤–æ–≥–æ –ø–æ–∏—Å–∫–∞"
                )
            return []

    def _update_search_index_by_chunks(self):
        """–°–æ–∑–¥–∞–µ—Ç –∏–Ω–¥–µ–∫—Å—ã –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞, –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—è —Ñ–∞–π–ª —á–∞—Å—Ç—è–º–∏"""
        logger.info("Updating search indexes by chunks...")
        self.search_index = {
            'okpd2': {},
            'name': set()
        }
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–µ–±–æ–ª—å—à–æ–π —Ä–∞–∑–º–µ—Ä —á–∞–Ω–∫–∞ –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏
        chunk_size = 5000
        total_processed = 0
        
        try:
            for chunk in pd.read_csv(
                self.GISP_FILE_PATH, 
                encoding='utf-8-sig',
                dtype={
                    '–ò–ù–ù': str,
                    '–†–µ–µ—Å—Ç—Ä–æ–≤—ã–π –Ω–æ–º–µ—Ä': str,
                    '–û–ö–ü–î2': str,
                    '–¢–ù –í–≠–î': str
                },
                chunksize=chunk_size
            ):
                # –ò–Ω–¥–µ–∫—Å –¥–ª—è –û–ö–ü–î2
                for idx, code in enumerate(chunk['–û–ö–ü–î2']):
                    if pd.notna(code):
                        code = str(code).lower()
                        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É –ø—Ä–µ—Ñ–∏–∫—Å–æ–≤ –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏
                        max_prefix_len = min(len(code), 5)  # –ï—â–µ –º–µ–Ω—å—à–µ –ø—Ä–µ—Ñ–∏–∫—Å–æ–≤
                        for i in range(max_prefix_len):
                            prefix = code[:i+1]
                            if prefix not in self.search_index['okpd2']:
                                self.search_index['okpd2'][prefix] = set()
                            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–π –∏–Ω–¥–µ–∫—Å
                            self.search_index['okpd2'][prefix].add(total_processed + idx)
                
                # –ò–Ω–¥–µ–∫—Å –¥–ª—è –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–π (—Ç–æ–ª—å–∫–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è)
                self.search_index['name'].update(
                    set(chunk['–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–¥—É–∫—Ü–∏–∏'].str.lower().dropna())
                )
                
                total_processed += len(chunk)
                
                # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏
                import gc
                del chunk
                gc.collect()
            
            logger.info(f"Search indexes updated successfully, processed {total_processed} rows")
            
        except Exception as e:
            logger.error(f"Error updating search indexes: {e}", exc_info=True)
            # –°–æ–∑–¥–∞–µ–º –ø—É—Å—Ç—ã–µ –∏–Ω–¥–µ–∫—Å—ã –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏
            self.search_index = {'okpd2': {}, 'name': set()}
        
        # –£–¥–∞–ª—è–µ–º —ç—Ç–æ—Ç –∫–æ–¥, —Ç–∞–∫ –∫–∞–∫ –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è df –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞
        # –ò–Ω–¥–µ–∫—Å –¥–ª—è –û–ö–ü–î2
        # for idx, code in enumerate(df['–û–ö–ü–î2']):
        #     if pd.notna(code):
        #         code = str(code).lower()
        #         for i in range(len(code)):
        #             prefix = code[:i+1]
        #             if prefix not in self.search_index['okpd2']:
        #                 self.search_index['okpd2'][prefix] = set()
        #             self.search_index['okpd2'][prefix].add(idx)
        
        # # –ò–Ω–¥–µ–∫—Å –¥–ª—è –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–π
        # self.search_index['name'] = set(df['–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–¥—É–∫—Ü–∏–∏'].str.lower().dropna())
        # logger.info("Search indexes updated successfully")

    async def search_gisp(self, okpd2: Optional[str] = None, name: Optional[str] = None, status_message=None) -> List[Dict]:
        try:
            if status_message:
                await status_message.edit_text("üîç –ù–∞—á–∏–Ω–∞–µ–º –ø–æ–∏—Å–∫ –≤ –ì–ò–°–ü...")

            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫—ç—à, –µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å
            if self.df_cache is None:
                if status_message:
                    await status_message.edit_text("üìñ –ó–∞–≥—Ä—É–∑–∫–∞ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö...")
                
                self.df_cache = pd.read_csv(
                    self.GISP_FILE_PATH,
                    encoding='utf-8-sig',
                    dtype={
                        '–ò–ù–ù': str,
                        '–†–µ–µ—Å—Ç—Ä–æ–≤—ã–π –Ω–æ–º–µ—Ä': str,
                        '–û–ö–ü–î2': str,
                        '–¢–ù –í–≠–î': str
                    }
                )
                # –ó–∞–º–µ–Ω—è–µ–º –≤—ã–∑–æ–≤ –Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ –º–µ—Ç–æ–¥–∞
                self._update_search_index_by_chunks()

            df = self.df_cache
            total_rows = len(df)

            if status_message:
                await status_message.edit_text("üîç –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Ñ–∏–ª—å—Ç—Ä–æ–≤...")

            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∏–Ω–¥–µ–∫—Å—ã –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞
            if okpd2 and name:
                okpd2_lower = okpd2.lower()
                name_lower = name.lower()
                
                # –ü–æ–∏—Å–∫ –ø–æ –û–ö–ü–î2
                potential_indices = self.search_index['okpd2'].get(okpd2_lower, set())
                mask = df.index.isin(potential_indices)
                
                # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏—é
                name_mask = df['–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–¥—É–∫—Ü–∏–∏'].str.lower().str.contains(name_lower, na=False)
                mask = mask & name_mask
                
            elif okpd2:
                okpd2_lower = okpd2.lower()
                potential_indices = self.search_index['okpd2'].get(okpd2_lower, set())
                mask = df.index.isin(potential_indices)
                
            elif name:
                name_lower = name.lower()
                mask = df['–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–¥—É–∫—Ü–∏–∏'].str.lower().str.contains(name_lower, na=False)
            else:
                return []

            # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            results = df[mask].to_dict('records')

            if status_message:
                await status_message.edit_text("üìä –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤...")
            
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ –Ω—É–∂–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç
            formatted_results = [{
                'name': row['–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–¥—É–∫—Ü–∏–∏'],
                'okpd2_code': row['–û–ö–ü–î2'],
                'manufacturer': row['–ü—Ä–µ–¥–ø—Ä–∏—è—Ç–∏–µ'],
                'inn': row['–ò–ù–ù'],
                'registry_number': row['–†–µ–µ—Å—Ç—Ä–æ–≤—ã–π –Ω–æ–º–µ—Ä'],
                'registry_date': row['–î–∞—Ç–∞ –≤–Ω–µ—Å–µ–Ω–∏—è –≤ —Ä–µ–µ—Å—Ç—Ä'],
                'valid_until': row['–°—Ä–æ–∫ –¥–µ–π—Å—Ç–≤–∏—è'],
                'tn_ved': row['–¢–ù –í–≠–î'],
                'standard': row['–ò–∑–≥–æ—Ç–æ–≤–ª–µ–Ω–∞ –ø–æ'],
                'source': '–ì–ò–°–ü'
            } for row in results]

            if status_message:
                found_count = len(formatted_results)
                await status_message.edit_text(
                    f"‚úÖ –ü–æ–∏—Å–∫ –∑–∞–≤–µ—Ä—à–µ–Ω\n"
                    f"üìä –ù–∞–π–¥–µ–Ω–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {found_count}\n"
                    f"üíæ –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π –≤ –±–∞–∑–µ: {total_rows}"
                )

            logger.info(f"GISP search completed, found {len(formatted_results)} results")
            return formatted_results

        except Exception as e:
            logger.error(f"GISP search error: {e}")
            if status_message:
                await status_message.edit_text(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ: {str(e)}")
            return []

    def start_background_updates(self):
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç —Ñ–æ–Ω–æ–≤–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Ñ–∞–π–ª–∞ –ì–ò–°–ü"""
        try:
            def update_job():
                logger.info("Running scheduled GISP update...")
                self.download_gisp_file()
                
            # –û–±–Ω–æ–≤–ª—è–µ–º —Ñ–∞–π–ª –∫–∞–∂–¥—ã–µ 7 –¥–Ω–µ–π
            schedule.every(7).days.do(update_job)
            
            # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫ –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ
            def run_scheduler():
                while True:
                    try:
                        schedule.run_pending()
                        time.sleep(3600)  # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑ –≤ —á–∞—Å
                    except Exception as e:
                        logger.error(f"Scheduler error: {e}")
                        time.sleep(3600)  # –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ –∂–¥–µ–º —á–∞—Å –∏ –ø—Ä–æ–±—É–µ–º —Å–Ω–æ–≤–∞
            
            scheduler_thread = threading.Thread(target=run_scheduler, daemon=True)
            scheduler_thread.start()
            logger.info("Background updates scheduled")
            
        except Exception as e:
            logger.error(f"Failed to start background updates: {e}")

    def download_gisp_file(self):
        """–°–∫–∞—á–∏–≤–∞–µ—Ç —Ñ–∞–π–ª –ì–ò–°–ü –±–µ–∑ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å—Ç–∞—Ç—É—Å–∞"""
        try:
            logger.info("Starting GISP file download (no status)...")
            temp_file = "data/temp_gisp.xlsx"
            
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                'Accept': '*/*',
                'Accept-Language': 'ru-RU,ru;q=0.9,en-US;q=0.8,en;q=0.7',
                'Accept-Encoding': 'gzip, deflate, br',
                'Connection': 'keep-alive',
                'Referer': 'https://gisp.gov.ru/',
            }
            
            self.GISP_EXCEL_URL = "https://gisp.gov.ru/pp719v2/mptapp/view/dl/production_res_valid_only/"
            
            response = requests.get(self.GISP_EXCEL_URL, headers=headers, verify=True, timeout=60)
            response.raise_for_status()
            
            with open(temp_file, 'wb') as f:
                f.write(response.content)
            
            logger.info("Processing GISP file...")
            
            # –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –±–µ–∑ —Å—Ç–∞—Ç—É—Å–∞
            chunk_size = 5000
            first_chunk = True
            total_rows = 0
            
            with open(self.GISP_FILE_PATH, 'w', encoding='utf-8-sig', newline='') as f:
                for chunk in pd.read_excel(
                    temp_file,
                    usecols=[0, 1, 6, 8, 9, 11, 12, 13, 14],
                    skiprows=2,
                    names=[
                        '–ü—Ä–µ–¥–ø—Ä–∏—è—Ç–∏–µ', '–ò–ù–ù', '–†–µ–µ—Å—Ç—Ä–æ–≤—ã–π –Ω–æ–º–µ—Ä', 
                        '–î–∞—Ç–∞ –≤–Ω–µ—Å–µ–Ω–∏—è –≤ —Ä–µ–µ—Å—Ç—Ä', '–°—Ä–æ–∫ –¥–µ–π—Å—Ç–≤–∏—è',
                        '–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–¥—É–∫—Ü–∏–∏', '–û–ö–ü–î2', '–¢–ù –í–≠–î', '–ò–∑–≥–æ—Ç–æ–≤–ª–µ–Ω–∞ –ø–æ'
                    ],
                    engine='openpyxl',
                    dtype={
                        '–ò–ù–ù': str,
                        '–†–µ–µ—Å—Ç—Ä–æ–≤—ã–π –Ω–æ–º–µ—Ä': str,
                        '–û–ö–ü–î2': str,
                        '–¢–ù –í–≠–î': str
                    },
                    chunksize=chunk_size
                ):
                    # –û—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏
                    import gc
                    gc.collect()
                    
                    # –û–±—Ä–∞–±–æ—Ç–∫–∞ —á–∞–Ω–∫–∞
                    chunk = chunk.dropna(how='all')
                    
                    # –ó–∞–ø–∏—Å—å –≤ CSV
                    if first_chunk:
                        chunk.to_csv(f, index=False)
                        first_chunk = False
                    else:
                        chunk.to_csv(f, index=False, header=False)
                    
                    total_rows += len(chunk)
                    
                    # –û—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏
                    del chunk
                    gc.collect()
            
            # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
            if os.path.exists(temp_file):
                os.remove(temp_file)
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –∏–Ω–¥–µ–∫—Å—ã
            self._update_search_index_by_chunks()
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –Ω–µ–±–æ–ª—å—à—É—é —á–∞—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö –≤ –∫—ç—à
            self.df_cache = pd.read_csv(
                self.GISP_FILE_PATH, 
                encoding='utf-8-sig',
                dtype={
                    '–ò–ù–ù': str,
                    '–†–µ–µ—Å—Ç—Ä–æ–≤—ã–π –Ω–æ–º–µ—Ä': str,
                    '–û–ö–ü–î2': str,
                    '–¢–ù –í–≠–î': str
                },
                nrows=1000
            )
            
            self.last_update = datetime.now()
            logger.info(f"GISP file updated successfully, total rows: {total_rows}")
            
        except Exception as e:
            logger.error(f"GISP file download failed: {e}", exc_info=True)
