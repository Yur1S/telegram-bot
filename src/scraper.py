import requests
import json
from typing import List, Dict, Optional
import logging
import pandas as pd
import os
from datetime import datetime, timedelta
import schedule
import time
import threading
import asyncio

logger = logging.getLogger(__name__)

class ProductScraper:
    def __init__(self):
        logger.info("Initializing ProductScraper...")
        self.EAEU_API_URL = "https://goszakupki.eaeunion.org/spd/find"
        self.GISP_EXCEL_URL = "https://gisp.gov.ru/documents/10546/11962150/reestr_pprf_719_27122023.xlsx"
        self.GISP_FILE_PATH = "data/gisp_products.csv"
        self.last_update = None
        self.file_update_status = None
        self.chunk_size = 50000
        self.df_cache = None
        self.search_index = {}  # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω–¥–µ–∫—Å –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞
        
        os.makedirs(os.path.dirname(self.GISP_FILE_PATH), exist_ok=True)
        self.start_background_updates()
        
        if not os.path.exists(self.GISP_FILE_PATH):
            logger.info("GISP file not found, downloading...")
            self.download_gisp_file()
        logger.info("ProductScraper initialized successfully")

    async def download_gisp_file_with_status(self, status_message):
        temp_file = "data/temp_gisp.xlsx"
        try:
            # –≠—Ç–∞–ø 1: –°–∫–∞—á–∏–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞
            logger.info("Starting GISP file download...")
            await status_message.edit_text("‚è≥ –°–∫–∞—á–∏–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞ –ì–ò–°–ü...")
            
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                'Accept': '*/*',
                'Accept-Language': 'ru-RU,ru;q=0.9,en-US;q=0.8,en;q=0.7',
                'Accept-Encoding': 'gzip, deflate, br',
                'Connection': 'keep-alive',
                'Referer': 'https://gisp.gov.ru/',
            }

            self.GISP_EXCEL_URL = "https://gisp.gov.ru/pp719v2/mptapp/view/dl/production_res_valid_only/"
            
            try:
                response = requests.get(self.GISP_EXCEL_URL, headers=headers, verify=True, timeout=60)
                response.raise_for_status()
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º Excel —Ñ–∞–π–ª
                with open(temp_file, 'wb') as f:
                    f.write(response.content)
                
                if not os.path.exists(temp_file) or os.path.getsize(temp_file) == 0:
                    raise Exception("Failed to download file or file is empty")
                
                logger.info(f"Excel file downloaded successfully, size: {os.path.getsize(temp_file)} bytes")
                
            except Exception as e:
                logger.error(f"Download failed: {str(e)}")
                raise Exception(f"Failed to download file: {str(e)}")

            # –≠—Ç–∞–ø 2: –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞
            # –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ Excel
            await status_message.edit_text("‚è≥ –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞ Excel...")
            try:
                logger.info(f"Starting Excel processing, file size: {os.path.getsize(temp_file)} bytes")
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ñ–∞–π–ª –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ Excel
                if os.path.getsize(temp_file) < 100:
                    raise Exception("–°–∫–∞—á–∞–Ω–Ω—ã–π —Ñ–∞–π–ª —Å–ª–∏—à–∫–æ–º –º–∞–ª–µ–Ω—å–∫–∏–π, –≤–æ–∑–º–æ–∂–Ω–æ —ç—Ç–æ –Ω–µ Excel")
                
                # –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ pandas
                pd.options.mode.chained_assignment = None
                chunk_size = 5000  # –£–º–µ–Ω—å—à–∞–µ–º —Ä–∞–∑–º–µ—Ä —á–∞–Ω–∫–∞ –µ—â–µ –±–æ–ª—å—à–µ
                
                # –ü—Ä–æ–±—É–µ–º –ø—Ä–æ—á–∏—Ç–∞—Ç—å –ø–µ—Ä–≤—ã–µ —Å—Ç—Ä–æ–∫–∏ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
                try:
                    test_df = pd.read_excel(
                        temp_file,
                        nrows=5,
                        skiprows=2,
                        engine='openpyxl'
                    )
                    logger.info(f"Excel test read successful, columns: {list(test_df.columns)}")
                    
                    # –û—Ü–µ–Ω–∏–≤–∞–µ–º –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
                    file_size = os.path.getsize(temp_file)
                    estimated_rows = int((file_size / (1024 * 1024)) * 5000)
                    logger.info(f"Estimated total rows: ~{estimated_rows} (based on file size {file_size/1024/1024:.2f} MB)")
                    
                except Exception as e:
                    logger.error(f"Excel test read failed: {str(e)}", exc_info=True)
                    raise Exception(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å Excel —Ñ–∞–π–ª: {str(e)}")
                
                # –ß–∏—Ç–∞–µ–º —Ç–æ–ª—å–∫–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –∫–æ–ª–æ–Ω–∫–∏ —Å –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ —Ç–∏–ø–∞–º–∏ –¥–∞–Ω–Ω—ã—Ö
                try:
                    df_iterator = pd.read_excel(
                        temp_file,
                        usecols=[0, 1, 6, 8, 9, 11, 12, 13, 14],
                        skiprows=2,
                        names=[
                            '–ü—Ä–µ–¥–ø—Ä–∏—è—Ç–∏–µ', '–ò–ù–ù', '–†–µ–µ—Å—Ç—Ä–æ–≤—ã–π –Ω–æ–º–µ—Ä', 
                            '–î–∞—Ç–∞ –≤–Ω–µ—Å–µ–Ω–∏—è –≤ —Ä–µ–µ—Å—Ç—Ä', '–°—Ä–æ–∫ –¥–µ–π—Å—Ç–≤–∏—è',
                            '–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–¥—É–∫—Ü–∏–∏', '–û–ö–ü–î2', '–¢–ù –í–≠–î', '–ò–∑–≥–æ—Ç–æ–≤–ª–µ–Ω–∞ –ø–æ'
                        ],
                        engine='openpyxl',
                        dtype={
                            '–ò–ù–ù': str,
                            '–†–µ–µ—Å—Ç—Ä–æ–≤—ã–π –Ω–æ–º–µ—Ä': str,
                            '–û–ö–ü–î2': str,
                            '–¢–ù –í–≠–î': str,
                            '–ü—Ä–µ–¥–ø—Ä–∏—è—Ç–∏–µ': str,
                            '–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–¥—É–∫—Ü–∏–∏': str,
                            '–ò–∑–≥–æ—Ç–æ–≤–ª–µ–Ω–∞ –ø–æ': str
                        },
                        chunksize=chunk_size
                    )
                except Exception as e:
                    logger.error(f"Excel iterator creation failed: {str(e)}", exc_info=True)
                    # –ü—Ä–æ–±—É–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –ø–æ–¥—Ö–æ–¥ –±–µ–∑ —É–∫–∞–∑–∞–Ω–∏—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫
                    df_iterator = pd.read_excel(
                        temp_file,
                        skiprows=2,
                        engine='openpyxl',
                        dtype=str,
                        chunksize=chunk_size
                    )
                    logger.info("Using alternative Excel reading approach")

                # –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —á–∞–Ω–∫–æ–≤
                first_chunk = True
                total_rows = 0
                start_time = time.time()
                last_update_time = time.time()
                
                with open(self.GISP_FILE_PATH, 'w', encoding='utf-8-sig', newline='') as f:
                    for i, chunk in enumerate(df_iterator):
                        # –û—á–∏—â–∞–µ–º –ø–∞–º—è—Ç—å –ø–µ—Ä–µ–¥ –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –Ω–æ–≤–æ–≥–æ —á–∞–Ω–∫–∞
                        import gc
                        gc.collect()
                        
                        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —á–∞–Ω–∫
                        chunk = chunk.dropna(how='all')
                        
                        # –õ–æ–≥–∏—Ä—É–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–µ—Ä–≤–æ–º —á–∞–Ω–∫–µ
                        if i == 0:
                            logger.info(f"First chunk columns: {list(chunk.columns)}")
                            logger.info(f"First chunk shape: {chunk.shape}")
                        
                        # –°–æ–∑–¥–∞–µ–º –∏–Ω–¥–µ–∫—Å—ã —Ç–æ–ª—å–∫–æ –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ —á–∞–Ω–∫–∞
                        if first_chunk:
                            chunk.to_csv(f, index=False)
                            first_chunk = False
                        else:
                            chunk.to_csv(f, index=False, header=False)
                        
                        total_rows += len(chunk)
                        
                        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –∫–∞–∂–¥—ã–µ 3 —Å–µ–∫—É–Ω–¥—ã –∏–ª–∏ –∫–∞–∂–¥—ã–µ 10000 —Å—Ç—Ä–æ–∫
                        current_time = time.time()
                        if current_time - last_update_time > 3 or total_rows % 10000 == 0:
                            elapsed_time = current_time - start_time
                            rows_per_second = total_rows / elapsed_time if elapsed_time > 0 else 0
                            
                            # –û—Ü–µ–Ω–∫–∞ –æ—Å—Ç–∞–≤—à–µ–≥–æ—Å—è –≤—Ä–µ–º–µ–Ω–∏
                            if rows_per_second > 0 and estimated_rows > total_rows:
                                remaining_rows = estimated_rows - total_rows
                                remaining_time = remaining_rows / rows_per_second
                                remaining_minutes = int(remaining_time / 60)
                                remaining_seconds = int(remaining_time % 60)
                                
                                progress = min(100, int((total_rows / estimated_rows) * 100))
                                
                                await status_message.edit_text(
                                    f"‚è≥ –û–±—Ä–∞–±–æ—Ç–∫–∞ Excel —Ñ–∞–π–ª–∞...\n"
                                    f"üìä –ü—Ä–æ–≥—Ä–µ—Å—Å: {progress}%\n"
                                    f"üìù –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Å—Ç—Ä–æ–∫: {total_rows:,} –∏–∑ ~{estimated_rows:,}\n"
                                    f"‚è±Ô∏è –°–∫–æ—Ä–æ—Å—Ç—å: {rows_per_second:.1f} —Å—Ç—Ä–æ–∫/—Å–µ–∫\n"
                                    f"üïí –û—Å—Ç–∞–ª–æ—Å—å –ø—Ä–∏–º–µ—Ä–Ω–æ: {remaining_minutes}–º {remaining_seconds}—Å"
                                )
                            else:
                                await status_message.edit_text(
                                    f"‚è≥ –û–±—Ä–∞–±–æ—Ç–∫–∞ Excel —Ñ–∞–π–ª–∞...\n"
                                    f"üìù –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Å—Ç—Ä–æ–∫: {total_rows:,}\n"
                                    f"‚è±Ô∏è –°–∫–æ—Ä–æ—Å—Ç—å: {rows_per_second:.1f} —Å—Ç—Ä–æ–∫/—Å–µ–∫"
                                )
                                
                            last_update_time = current_time
                        
                        # –û—á–∏—â–∞–µ–º –ø–∞–º—è—Ç—å
                        del chunk
                        gc.collect()

                logger.info(f"CSV file saved successfully, total rows: {total_rows}")
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ CSV —Ñ–∞–π–ª –Ω–µ –ø—É—Å—Ç–æ–π
                if os.path.getsize(self.GISP_FILE_PATH) == 0:
                    raise Exception("CSV —Ñ–∞–π–ª —Å–æ–∑–¥–∞–Ω, –Ω–æ –∏–º–µ–µ—Ç –Ω—É–ª–µ–≤–æ–π —Ä–∞–∑–º–µ—Ä")
                
                # –û–±–Ω–æ–≤–ª—è–µ–º –∏–Ω–¥–µ–∫—Å—ã —á–∞—Å—Ç—è–º–∏
                await status_message.edit_text("‚è≥ –°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–æ–≤ –ø–æ–∏—Å–∫–∞...")
                self._update_search_index_by_chunks()
                
                # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
                if os.path.exists(temp_file):
                    os.remove(temp_file)
                    logger.info("Temporary Excel file removed")
                
                await status_message.edit_text("‚úÖ –§–∞–π–ª –ì–ò–°–ü —É—Å–ø–µ—à–Ω–æ –æ–±–Ω–æ–≤–ª–µ–Ω!")
                self.last_update = datetime.now()
                
                # –ó–∞–≥—Ä—É–∂–∞–µ–º –Ω–µ–±–æ–ª—å—à—É—é —á–∞—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö –≤ –∫—ç—à
                self.df_cache = pd.read_csv(
                    self.GISP_FILE_PATH, 
                    encoding='utf-8-sig',
                    dtype={
                        '–ò–ù–ù': str,
                        '–†–µ–µ—Å—Ç—Ä–æ–≤—ã–π –Ω–æ–º–µ—Ä': str,
                        '–û–ö–ü–î2': str,
                        '–¢–ù –í–≠–î': str
                    },
                    nrows=1000
                )
                
                return total_rows
                
            except Exception as e:
                logger.error(f"Excel processing failed: {str(e)}", exc_info=True)
                await status_message.edit_text(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞: {str(e)}")
                raise
                
        except Exception as e:
            logger.error(f"GISP file download failed: {str(e)}", exc_info=True)
            await status_message.edit_text(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Ñ–∞–π–ª–∞: {str(e)}")
            return 0

    def search_eaeu(self, okpd2: Optional[str] = None, name: Optional[str] = None) -> List[Dict]:
        try:
            logger.info(f"Starting EAEU search with okpd2={okpd2}, name={name}")
            params = {
                "collection": "db1.v_goodscollection_prod_public",
                "limit": 1000,
                "skip": 0,
                "sort": {"publishdate": -1}
            }

            query_filter = {}
            if okpd2:
                query_filter["okpd2.code"] = {"$regex": f"^{okpd2}", "$options": "i"}
            if name:
                query_filter["name"] = {"$regex": name, "$options": "i"}

            if query_filter:
                params["filter"] = query_filter

            response = requests.post(self.EAEU_API_URL, json=params)
            response.raise_for_status()
            
            data = response.json()
            
            results = []
            for item in data.get('items', []):
                result = {
                    'name': item.get('name', ''),
                    'okpd2_code': item.get('okpd2', {}).get('code', ''),
                    'manufacturer': item.get('manufacturer', {}).get('name', ''),
                    'inn': '',
                    'registry_number': '',
                    'registry_date': '',
                    'valid_until': '',
                    'tn_ved': '',
                    'standard': '',
                    'source': '–ï–ê–≠–°'
                }
                results.append(result)
            
            logger.info(f"EAEU search completed, found {len(results)} results")
            return results

        except Exception as e:
            logger.error(f"EAEU API search error: {e}")
            return []

    async def search_all(self, okpd2: Optional[str] = None, name: Optional[str] = None, status_message=None) -> List[Dict]:
        try:
            logger.info(f"Starting combined search with okpd2={okpd2}, name={name}")
            
            if status_message:
                await status_message.edit_text(
                    "üîç –ü–æ–∏—Å–∫ –≤ –ï–ê–≠–°...\n"
                    "‚è≥ –ü—Ä–æ–≥—Ä–µ—Å—Å: 0%"
                )
            eaeu_results = self.search_eaeu(okpd2, name)
            
            if status_message:
                await status_message.edit_text(
                    "üîç –ü–æ–∏—Å–∫ –≤ –ì–ò–°–ü...\n"
                    "‚è≥ –ü—Ä–æ–≥—Ä–µ—Å—Å: 50%"
                )
            gisp_results = await self.search_gisp(okpd2, name, status_message)
            
            total_results = eaeu_results + gisp_results
            
            if status_message:
                await status_message.edit_text(
                    f"‚úÖ –ü–æ–∏—Å–∫ –∑–∞–≤–µ—Ä—à–µ–Ω\n"
                    f"üìä –í—Å–µ–≥–æ –Ω–∞–π–¥–µ–Ω–æ: {len(total_results)}\n"
                    f"–ï–ê–≠–°: {len(eaeu_results)}\n"
                    f"–ì–ò–°–ü: {len(gisp_results)}\n\n"
                    f"–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ /start –¥–ª—è –Ω–æ–≤–æ–≥–æ –ø–æ–∏—Å–∫–∞"
                )
            
            logger.info(f"Combined search completed, total results: {len(total_results)}")
            return total_results
            
        except Exception as e:
            logger.error(f"Combined search error: {e}")
            if status_message:
                await status_message.edit_text(
                    f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ: {str(e)}\n\n"
                    f"–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ /start –¥–ª—è –Ω–æ–≤–æ–≥–æ –ø–æ–∏—Å–∫–∞"
                )
            return []

    def _update_search_index_by_chunks(self):
        """–°–æ–∑–¥–∞–µ—Ç –∏–Ω–¥–µ–∫—Å—ã –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞, –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—è —Ñ–∞–π–ª —á–∞—Å—Ç—è–º–∏"""
        logger.info("Updating search indexes by chunks...")
        self.search_index = {
            'okpd2': {},
            'name': set()
        }
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–µ–±–æ–ª—å—à–æ–π —Ä–∞–∑–º–µ—Ä —á–∞–Ω–∫–∞ –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏
        chunk_size = 5000
        total_processed = 0
        
        try:
            for chunk in pd.read_csv(
                self.GISP_FILE_PATH, 
                encoding='utf-8-sig',
                dtype={
                    '–ò–ù–ù': str,
                    '–†–µ–µ—Å—Ç—Ä–æ–≤—ã–π –Ω–æ–º–µ—Ä': str,
                    '–û–ö–ü–î2': str,
                    '–¢–ù –í–≠–î': str
                },
                chunksize=chunk_size
            ):
                # –ò–Ω–¥–µ–∫—Å –¥–ª—è –û–ö–ü–î2
                for idx, code in enumerate(chunk['–û–ö–ü–î2']):
                    if pd.notna(code):
                        code = str(code).lower()
                        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É –ø—Ä–µ—Ñ–∏–∫—Å–æ–≤ –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏
                        max_prefix_len = min(len(code), 5)  # –ï—â–µ –º–µ–Ω—å—à–µ –ø—Ä–µ—Ñ–∏–∫—Å–æ–≤
                        for i in range(max_prefix_len):
                            prefix = code[:i+1]
                            if prefix not in self.search_index['okpd2']:
                                self.search_index['okpd2'][prefix] = set()
                            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–π –∏–Ω–¥–µ–∫—Å
                            self.search_index['okpd2'][prefix].add(total_processed + idx)
                
                # –ò–Ω–¥–µ–∫—Å –¥–ª—è –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–π (—Ç–æ–ª—å–∫–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è)
                self.search_index['name'].update(
                    set(chunk['–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–¥—É–∫—Ü–∏–∏'].str.lower().dropna())
                )
                
                total_processed += len(chunk)
                
                # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏
                import gc
                del chunk
                gc.collect()
            
            logger.info(f"Search indexes updated successfully, processed {total_processed} rows")
            
        except Exception as e:
            logger.error(f"Error updating search indexes: {e}", exc_info=True)
            # –°–æ–∑–¥–∞–µ–º –ø—É—Å—Ç—ã–µ –∏–Ω–¥–µ–∫—Å—ã –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏
            self.search_index = {'okpd2': {}, 'name': set()}
        
        # –£–¥–∞–ª—è–µ–º —ç—Ç–æ—Ç –∫–æ–¥, —Ç–∞–∫ –∫–∞–∫ –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è df –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞
        # –ò–Ω–¥–µ–∫—Å –¥–ª—è –û–ö–ü–î2
        # for idx, code in enumerate(df['–û–ö–ü–î2']):
        #     if pd.notna(code):
        #         code = str(code).lower()
        #         for i in range(len(code)):
        #             prefix = code[:i+1]
        #             if prefix not in self.search_index['okpd2']:
        #                 self.search_index['okpd2'][prefix] = set()
        #             self.search_index['okpd2'][prefix].add(idx)
        
        # # –ò–Ω–¥–µ–∫—Å –¥–ª—è –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–π
        # self.search_index['name'] = set(df['–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–¥—É–∫—Ü–∏–∏'].str.lower().dropna())
        # logger.info("Search indexes updated successfully")

    async def search_gisp(self, okpd2: Optional[str] = None, name: Optional[str] = None, status_message=None) -> List[Dict]:
        try:
            if status_message:
                await status_message.edit_text("üîç –ù–∞—á–∏–Ω–∞–µ–º –ø–æ–∏—Å–∫ –≤ –ì–ò–°–ü...")

            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫—ç—à, –µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å
            if self.df_cache is None:
                if status_message:
                    await status_message.edit_text("üìñ –ó–∞–≥—Ä—É–∑–∫–∞ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö...")
                
                self.df_cache = pd.read_csv(
                    self.GISP_FILE_PATH,
                    encoding='utf-8-sig',
                    dtype={
                        '–ò–ù–ù': str,
                        '–†–µ–µ—Å—Ç—Ä–æ–≤—ã–π –Ω–æ–º–µ—Ä': str,
                        '–û–ö–ü–î2': str,
                        '–¢–ù –í–≠–î': str
                    }
                )
                # –ó–∞–º–µ–Ω—è–µ–º –≤—ã–∑–æ–≤ –Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ –º–µ—Ç–æ–¥–∞
                self._update_search_index_by_chunks()

            df = self.df_cache
            total_rows = len(df)

            if status_message:
                await status_message.edit_text("üîç –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Ñ–∏–ª—å—Ç—Ä–æ–≤...")

            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∏–Ω–¥–µ–∫—Å—ã –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞
            if okpd2 and name:
                okpd2_lower = okpd2.lower()
                name_lower = name.lower()
                
                # –ü–æ–∏—Å–∫ –ø–æ –û–ö–ü–î2
                potential_indices = self.search_index['okpd2'].get(okpd2_lower, set())
                mask = df.index.isin(potential_indices)
                
                # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏—é
                name_mask = df['–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–¥—É–∫—Ü–∏–∏'].str.lower().str.contains(name_lower, na=False)
                mask = mask & name_mask
                
            elif okpd2:
                okpd2_lower = okpd2.lower()
                potential_indices = self.search_index['okpd2'].get(okpd2_lower, set())
                mask = df.index.isin(potential_indices)
                
            elif name:
                name_lower = name.lower()
                mask = df['–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–¥—É–∫—Ü–∏–∏'].str.lower().str.contains(name_lower, na=False)
            else:
                return []

            # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            results = df[mask].to_dict('records')

            if status_message:
                await status_message.edit_text("üìä –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤...")
            
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ –Ω—É–∂–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç
            formatted_results = [{
                'name': row['–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–¥—É–∫—Ü–∏–∏'],
                'okpd2_code': row['–û–ö–ü–î2'],
                'manufacturer': row['–ü—Ä–µ–¥–ø—Ä–∏—è—Ç–∏–µ'],
                'inn': row['–ò–ù–ù'],
                'registry_number': row['–†–µ–µ—Å—Ç—Ä–æ–≤—ã–π –Ω–æ–º–µ—Ä'],
                'registry_date': row['–î–∞—Ç–∞ –≤–Ω–µ—Å–µ–Ω–∏—è –≤ —Ä–µ–µ—Å—Ç—Ä'],
                'valid_until': row['–°—Ä–æ–∫ –¥–µ–π—Å—Ç–≤–∏—è'],
                'tn_ved': row['–¢–ù –í–≠–î'],
                'standard': row['–ò–∑–≥–æ—Ç–æ–≤–ª–µ–Ω–∞ –ø–æ'],
                'source': '–ì–ò–°–ü'
            } for row in results]

            if status_message:
                found_count = len(formatted_results)
                await status_message.edit_text(
                    f"‚úÖ –ü–æ–∏—Å–∫ –∑–∞–≤–µ—Ä—à–µ–Ω\n"
                    f"üìä –ù–∞–π–¥–µ–Ω–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {found_count}\n"
                    f"üíæ –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π –≤ –±–∞–∑–µ: {total_rows}"
                )

            logger.info(f"GISP search completed, found {len(formatted_results)} results")
            return formatted_results

        except Exception as e:
            logger.error(f"GISP search error: {e}")
            if status_message:
                await status_message.edit_text(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ: {str(e)}")
            return []

    def start_background_updates(self):
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç —Ñ–æ–Ω–æ–≤–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Ñ–∞–π–ª–∞ –ì–ò–°–ü"""
        try:
            def update_job():
                logger.info("Running scheduled GISP update...")
                self.download_gisp_file()
                
            # –û–±–Ω–æ–≤–ª—è–µ–º —Ñ–∞–π–ª –∫–∞–∂–¥—ã–µ 7 –¥–Ω–µ–π
            schedule.every(7).days.do(update_job)
            
            # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫ –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ
            def run_scheduler():
                while True:
                    try:
                        schedule.run_pending()
                        time.sleep(3600)  # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑ –≤ —á–∞—Å
                    except Exception as e:
                        logger.error(f"Scheduler error: {e}")
                        time.sleep(3600)  # –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ –∂–¥–µ–º —á–∞—Å –∏ –ø—Ä–æ–±—É–µ–º —Å–Ω–æ–≤–∞
            
            scheduler_thread = threading.Thread(target=run_scheduler, daemon=True)
            scheduler_thread.start()
            logger.info("Background updates scheduled")
            
        except Exception as e:
            logger.error(f"Failed to start background updates: {e}")

    def download_gisp_file(self):
        """–°–∫–∞—á–∏–≤–∞–µ—Ç —Ñ–∞–π–ª –ì–ò–°–ü –±–µ–∑ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å—Ç–∞—Ç—É—Å–∞"""
        try:
            logger.info("Starting GISP file download (no status)...")
            temp_file = "data/temp_gisp.xlsx"
            
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                'Accept': '*/*',
                'Accept-Language': 'ru-RU,ru;q=0.9,en-US;q=0.8,en;q=0.7',
                'Accept-Encoding': 'gzip, deflate, br',
                'Connection': 'keep-alive',
                'Referer': 'https://gisp.gov.ru/',
            }
            
            self.GISP_EXCEL_URL = "https://gisp.gov.ru/pp719v2/mptapp/view/dl/production_res_valid_only/"
            
            response = requests.get(self.GISP_EXCEL_URL, headers=headers, verify=True, timeout=60)
            response.raise_for_status()
            
            with open(temp_file, 'wb') as f:
                f.write(response.content)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ñ–∞–π–ª –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ Excel
            if os.path.getsize(temp_file) < 100:
                raise Exception("–°–∫–∞—á–∞–Ω–Ω—ã–π —Ñ–∞–π–ª —Å–ª–∏—à–∫–æ–º –º–∞–ª–µ–Ω—å–∫–∏–π, –≤–æ–∑–º–æ–∂–Ω–æ —ç—Ç–æ –Ω–µ Excel")
            
            logger.info("Processing GISP file...")
            
            # –ü—Ä–æ–±—É–µ–º –ø—Ä–æ—á–∏—Ç–∞—Ç—å –ø–µ—Ä–≤—ã–µ —Å—Ç—Ä–æ–∫–∏ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
            try:
                test_df = pd.read_excel(
                    temp_file,
                    nrows=5,
                    skiprows=2,
                    engine='openpyxl'
                )
                logger.info(f"Excel test read successful, columns: {list(test_df.columns)}")
                
                # –û—Ü–µ–Ω–∏–≤–∞–µ–º –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
                file_size = os.path.getsize(temp_file)
                estimated_rows = int((file_size / (1024 * 1024)) * 5000)
                logger.info(f"Estimated total rows: ~{estimated_rows} (based on file size {file_size/1024/1024:.2f} MB)")
                
            except Exception as e:
                logger.error(f"Excel test read failed: {str(e)}", exc_info=True)
                raise Exception(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å Excel —Ñ–∞–π–ª: {str(e)}")
            
            # –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –±–µ–∑ —Å—Ç–∞—Ç—É—Å–∞
            chunk_size = 5000
            first_chunk = True
            total_rows = 0
            last_progress_time = time.time()
            start_time = time.time()
            
            with open(self.GISP_FILE_PATH, 'w', encoding='utf-8-sig', newline='') as f:
                try:
                    for chunk in pd.read_excel(
                        temp_file,
                        usecols=[0, 1, 6, 8, 9, 11, 12, 13, 14],
                        skiprows=2,
                        names=[
                            '–ü—Ä–µ–¥–ø—Ä–∏—è—Ç–∏–µ', '–ò–ù–ù', '–†–µ–µ—Å—Ç—Ä–æ–≤—ã–π –Ω–æ–º–µ—Ä', 
                            '–î–∞—Ç–∞ –≤–Ω–µ—Å–µ–Ω–∏—è –≤ —Ä–µ–µ—Å—Ç—Ä', '–°—Ä–æ–∫ –¥–µ–π—Å—Ç–≤–∏—è',
                            '–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–¥—É–∫—Ü–∏–∏', '–û–ö–ü–î2', '–¢–ù –í–≠–î', '–ò–∑–≥–æ—Ç–æ–≤–ª–µ–Ω–∞ –ø–æ'
                        ],
                        engine='openpyxl',
                        dtype={
                            '–ò–ù–ù': str,
                            '–†–µ–µ—Å—Ç—Ä–æ–≤—ã–π –Ω–æ–º–µ—Ä': str,
                            '–û–ö–ü–î2': str,
                            '–¢–ù –í–≠–î': str
                        },
                        chunksize=chunk_size
                    ):
                        # –û—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏
                        import gc
                        gc.collect()
                        
                        # –û–±—Ä–∞–±–æ—Ç–∫–∞ —á–∞–Ω–∫–∞
                        chunk = chunk.dropna(how='all')
                        
                        # –õ–æ–≥–∏—Ä—É–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–µ—Ä–≤–æ–º —á–∞–Ω–∫–µ
                        if first_chunk:
                            logger.info(f"First chunk columns: {list(chunk.columns)}")
                            logger.info(f"First chunk shape: {chunk.shape}")
                        
                        # –ó–∞–ø–∏—Å—å –≤ CSV
                        if first_chunk:
                            chunk.to_csv(f, index=False)
                            first_chunk = False
                        else:
                            chunk.to_csv(f, index=False, header=False)
                        
                        total_rows += len(chunk)
                        
                        # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –∫–∞–∂–¥—ã–µ 5 —Å–µ–∫—É–Ω–¥
                        current_time = time.time()
                        if current_time - last_progress_time > 5:
                            elapsed_time = current_time - start_time
                            rows_per_second = total_rows / elapsed_time if elapsed_time > 0 else 0
                            
                            # –û—Ü–µ–Ω–∫–∞ –æ—Å—Ç–∞–≤—à–µ–≥–æ—Å—è –≤—Ä–µ–º–µ–Ω–∏
                            if rows_per_second > 0 and estimated_rows > total_rows:
                                remaining_rows = estimated_rows - total_rows
                                remaining_time = remaining_rows / rows_per_second
                                remaining_minutes = int(remaining_time / 60)
                                remaining_seconds = int(remaining_time % 60)
                                
                                progress = min(100, int((total_rows / estimated_rows) * 100))
                                
                                logger.info(
                                    f"Progress: {progress}% - Processed {total_rows:,} rows "
                                    f"({rows_per_second:.1f} rows/sec) - "
                                    f"Est. remaining: {remaining_minutes}m {remaining_seconds}s"
                                )
                            else:
                                logger.info(f"Processed {total_rows:,} rows ({rows_per_second:.1f} rows/sec)")
                                
                            last_progress_time = current_time
                        
                        # –û—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏
                        del chunk
                        gc.collect()
                except Exception as e:
                    logger.error(f"Excel processing failed: {str(e)}", exc_info=True)
                    # –ü—Ä–æ–±—É–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –ø–æ–¥—Ö–æ–¥ –±–µ–∑ —É–∫–∞–∑–∞–Ω–∏—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫
                    f.seek(0)  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º—Å—è –≤ –Ω–∞—á–∞–ª–æ —Ñ–∞–π–ª–∞
                    first_chunk = True
                    total_rows = 0
                    
                    # –ß–∏—Ç–∞–µ–º –≤–µ—Å—å —Ñ–∞–π–ª –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º —á–∞—Å—Ç—è–º–∏
                    df = pd.read_excel(
                        temp_file,
                        skiprows=2,
                        engine='openpyxl',
                        dtype=str
                    )
                    
                    total_rows = len(df)
                    chunk_size = 5000
                    
                    for i in range(0, total_rows, chunk_size):
                        chunk = df.iloc[i:i+chunk_size]
                        mode = 'w' if i == 0 else 'a'
                        chunk.to_csv(
                            self.GISP_FILE_PATH,
                            mode=mode,
                            index=False,
                            header=(i == 0),
                            encoding='utf-8-sig'
                        )
                        
                        # –û—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏
                        del chunk
                        gc.collect()
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ CSV —Ñ–∞–π–ª –Ω–µ –ø—É—Å—Ç–æ–π
            if os.path.getsize(self.GISP_FILE_PATH) == 0:
                raise Exception("CSV —Ñ–∞–π–ª —Å–æ–∑–¥–∞–Ω, –Ω–æ –∏–º–µ–µ—Ç –Ω—É–ª–µ–≤–æ–π —Ä–∞–∑–º–µ—Ä")
            
            # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
            if os.path.exists(temp_file):
                os.remove(temp_file)
                logger.info("Temporary Excel file removed")
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –∏–Ω–¥–µ–∫—Å—ã
            self._update_search_index_by_chunks()
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –Ω–µ–±–æ–ª—å—à—É—é —á–∞—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö –≤ –∫—ç—à
            self.df_cache = pd.read_csv(
                self.GISP_FILE_PATH, 
                encoding='utf-8-sig',
                dtype={
                    '–ò–ù–ù': str,
                    '–†–µ–µ—Å—Ç—Ä–æ–≤—ã–π –Ω–æ–º–µ—Ä': str,
                    '–û–ö–ü–î2': str,
                    '–¢–ù –í–≠–î': str
                },
                nrows=1000
            )
            
            self.last_update = datetime.now()
            logger.info(f"GISP file updated successfully, total rows: {total_rows}")
            
        except Exception as e:
            logger.error(f"GISP file download failed: {e}", exc_info=True)
